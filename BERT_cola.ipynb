{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BERT_cola.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMlWr41ypFqxmfwjQF1pLGi"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"b909c4b8a71c4878b721d0e8c26cde16":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_c63f078587aa435a80c659ed6eac5030","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_a3e06726e587484dab11d1658f537fac","IPY_MODEL_d69a880ad722475e9d189cc4c81602f4"]}},"c63f078587aa435a80c659ed6eac5030":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a3e06726e587484dab11d1658f537fac":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_08dfc8f1d2e6495fbceef929d84d31f1","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":433,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":433,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7a3575b043894cc0bf69549851aee20b"}},"d69a880ad722475e9d189cc4c81602f4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_9419597e3f2e405293a032f4b976553c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 433/433 [00:15&lt;00:00, 27.5B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a32c674bb55d4c93957be656df874a8c"}},"08dfc8f1d2e6495fbceef929d84d31f1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"7a3575b043894cc0bf69549851aee20b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9419597e3f2e405293a032f4b976553c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a32c674bb55d4c93957be656df874a8c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cc24ddcbe0ad4a0ca4b9a8374e5748dd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_adc60a63d82b48e9b6a9a1e8dc3017b5","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b1a76dc6b43a4515b2ecad108243b860","IPY_MODEL_36692c11bf24498c86ad13afec5970f4"]}},"adc60a63d82b48e9b6a9a1e8dc3017b5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b1a76dc6b43a4515b2ecad108243b860":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_80efeda32e6646f19851e0c203a536b9","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":440473133,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":440473133,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a9ecd68c790443c9bd6c73e1398fe70e"}},"36692c11bf24498c86ad13afec5970f4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a6575818001f47278751346adf84f6f6","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 440M/440M [00:15&lt;00:00, 28.6MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3a049448edc8457e8d2c28d5a8e31d41"}},"80efeda32e6646f19851e0c203a536b9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"a9ecd68c790443c9bd6c73e1398fe70e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a6575818001f47278751346adf84f6f6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3a049448edc8457e8d2c28d5a8e31d41":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"Bf8NE4Q1MmJ5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":615},"executionInfo":{"status":"ok","timestamp":1599939071268,"user_tz":420,"elapsed":6745,"user":{"displayName":"Dillon Quan","photoUrl":"","userId":"05921916562389664894"}},"outputId":"20eaaa80-7f61-47f4-f35d-22b3fef97b26"},"source":["!pip install transformers"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/05/c8c55b600308dc04e95100dc8ad8a244dd800fe75dfafcf1d6348c6f6209/transformers-3.1.0-py3-none-any.whl (884kB)\n","\u001b[K     |████████████████████████████████| 890kB 4.6MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n","Collecting sentencepiece!=0.1.92\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 23.3MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n","Collecting tokenizers==0.8.1.rc2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/83/8b9fccb9e48eeb575ee19179e2bdde0ee9a1904f97de5f02d19016b8804f/tokenizers-0.8.1rc2-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n","\u001b[K     |████████████████████████████████| 3.0MB 31.7MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 46.2MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=37f5442434c6e3d1b6fc2b9f00a388b2e592ff0cfdc761b60b5ff79ca29677d9\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: sentencepiece, tokenizers, sacremoses, transformers\n","Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc2 transformers-3.1.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"j_FHB_trMrZL","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599939073082,"user_tz":420,"elapsed":6464,"user":{"displayName":"Dillon Quan","photoUrl":"","userId":"05921916562389664894"}}},"source":["import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import BertTokenizer, BertModel"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"sZ1b4gNGM_8o","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1599939073593,"user_tz":420,"elapsed":2824,"user":{"displayName":"Dillon Quan","photoUrl":"","userId":"05921916562389664894"}},"outputId":"e33ff901-1acb-49e7-e771-7f13c6332c04"},"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","device"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'cuda'"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"txG-O5ngNU9i","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1599939078107,"user_tz":420,"elapsed":1110,"user":{"displayName":"Dillon Quan","photoUrl":"","userId":"05921916562389664894"}},"outputId":"0cc1298c-00ec-4877-db16-b5305aad2618"},"source":["def get_data():\n","    ! wget https://nyu-mll.github.io/CoLA/cola_public_1.1.zip\n","    ! mkdir data\n","    ! unzip -q cola_public_1.1.zip -d ./data\n","get_data()"],"execution_count":5,"outputs":[{"output_type":"stream","text":["--2020-09-12 19:31:16--  https://nyu-mll.github.io/CoLA/cola_public_1.1.zip\n","Resolving nyu-mll.github.io (nyu-mll.github.io)... 185.199.108.153, 185.199.111.153, 185.199.109.153, ...\n","Connecting to nyu-mll.github.io (nyu-mll.github.io)|185.199.108.153|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 255330 (249K) [application/zip]\n","Saving to: ‘cola_public_1.1.zip’\n","\n","cola_public_1.1.zip 100%[===================>] 249.35K  --.-KB/s    in 0.03s   \n","\n","2020-09-12 19:31:17 (7.22 MB/s) - ‘cola_public_1.1.zip’ saved [255330/255330]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sXmKJD4fSPSn","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1599939081695,"user_tz":420,"elapsed":582,"user":{"displayName":"Dillon Quan","photoUrl":"","userId":"05921916562389664894"}},"outputId":"c790a247-79e7-4e11-92bb-cbb38bd33718"},"source":["df = pd.read_csv('./data/cola_public/raw/in_domain_train.tsv', delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n","df.head()"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentence_source</th>\n","      <th>label</th>\n","      <th>label_notes</th>\n","      <th>sentence</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>gj04</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","      <td>Our friends won't buy this analysis, let alone...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>gj04</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","      <td>One more pseudo generalization and I'm giving up.</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>gj04</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","      <td>One more pseudo generalization or I'm giving up.</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>gj04</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","      <td>The more we study verbs, the crazier they get.</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>gj04</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","      <td>Day by day the facts are getting murkier.</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  sentence_source  ...                                           sentence\n","0            gj04  ...  Our friends won't buy this analysis, let alone...\n","1            gj04  ...  One more pseudo generalization and I'm giving up.\n","2            gj04  ...   One more pseudo generalization or I'm giving up.\n","3            gj04  ...     The more we study verbs, the crazier they get.\n","4            gj04  ...          Day by day the facts are getting murkier.\n","\n","[5 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"RXhjJLbdTHK5","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599939084624,"user_tz":420,"elapsed":417,"user":{"displayName":"Dillon Quan","photoUrl":"","userId":"05921916562389664894"}}},"source":["class GLUE(Dataset):\n","    def __init__(self, data, tokenizer, max_len):\n","        super().__init__()\n","        self.X = data.sentence.values\n","        self.y = data.label.values\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","\n","    def __len__(self):\n","        return len(self.X)\n","    \n","    def __getitem__(self, idx):\n","        inputs = self.tokenizer.tokenize(self.X[idx])\n","        inputs = self.tokenizer.encode_plus(inputs,\n","                                            add_special_tokens=True,\n","                                            max_length=self.max_len,\n","                                            pad_to_max_length=True,\n","                                            truncation=True)\n","        \n","        return torch.LongTensor(inputs['input_ids']), torch.LongTensor(inputs['attention_mask']), self.y[idx]\n"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"5Aa4C2EMWX8y","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599941198942,"user_tz":420,"elapsed":385,"user":{"displayName":"Dillon Quan","photoUrl":"","userId":"05921916562389664894"}}},"source":["MAX_LEN = 128\n","TRAIN_BATCH_SIZE = 16\n","VALID_BATCH_SIZE = 8\n","EPOCHS = 4\n","LEARNING_RATE = 3e-5\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"],"execution_count":57,"outputs":[]},{"cell_type":"code","metadata":{"id":"mmMPSPSJUMNC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":411},"executionInfo":{"status":"ok","timestamp":1599939100172,"user_tz":420,"elapsed":394,"user":{"displayName":"Dillon Quan","photoUrl":"","userId":"05921916562389664894"}},"outputId":"cfa6cb5f-8875-4349-c346-d9961a8da8b8"},"source":["# testing the dataset\n","test = GLUE(df.head(), tokenizer, MAX_LEN)\n","test[0]"],"execution_count":9,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["(tensor([  101,  2256,  2814,  2180,  1005,  1056,  4965,  2023,  4106,  1010,\n","          2292,  2894,  1996,  2279,  2028,  2057, 16599,  1012,   102,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0]),\n"," tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0]),\n"," 1)"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"LrgPe7_9UNDI","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599939116646,"user_tz":420,"elapsed":415,"user":{"displayName":"Dillon Quan","photoUrl":"","userId":"05921916562389664894"}}},"source":["# splitting up the data and throwing it in a dataloader\n","from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, _, _ = train_test_split(df, df.label, test_size=.2, random_state=42)\n","train_ds = GLUE(X_train, tokenizer, MAX_LEN)\n","valid_ds = GLUE(X_test, tokenizer, MAX_LEN)\n","\n","train_dl = DataLoader(train_ds, shuffle=True, batch_size=TRAIN_BATCH_SIZE)\n","valid_dl = DataLoader(valid_ds, batch_size=VALID_BATCH_SIZE)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"uWupd-wsX8bI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":190},"executionInfo":{"status":"ok","timestamp":1599939122360,"user_tz":420,"elapsed":362,"user":{"displayName":"Dillon Quan","photoUrl":"","userId":"05921916562389664894"}},"outputId":"3b95ec51-44e2-4f86-b716-b3ada8b99f5e"},"source":["x, mask, y = next(iter(train_dl))\n","x"],"execution_count":11,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["tensor([[  101,  1996,  9540,  ...,     0,     0,     0],\n","        [  101,  5742,  2003,  ...,     0,     0,     0],\n","        [  101,  2952,  1051,  ...,     0,     0,     0],\n","        ...,\n","        [  101,  2984, 16849,  ...,     0,     0,     0],\n","        [  101, 20328, 17645,  ...,     0,     0,     0],\n","        [  101,  1045,  2404,  ...,     0,     0,     0]])"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"8dOsYQrQX-L9","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1599939124616,"user_tz":420,"elapsed":385,"user":{"displayName":"Dillon Quan","photoUrl":"","userId":"05921916562389664894"}},"outputId":"db786299-c788-4dec-af67-310ff0d1c0a8"},"source":["x.size(), mask.size(), y.size()"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([16, 128]), torch.Size([16, 128]), torch.Size([16]))"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"E8Mxh3umYzBI","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599939131917,"user_tz":420,"elapsed":382,"user":{"displayName":"Dillon Quan","photoUrl":"","userId":"05921916562389664894"}}},"source":["class BERT(nn.Module):\n","    def __init__(self, dropout):\n","        super().__init__()\n","        self.bert = BertModel.from_pretrained('bert-base-uncased')\n","        self.pre_classifier = torch.nn.Linear(768, 768)\n","        self.classifier = torch.nn.Linear(768, 1)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, input_ids, attention_mask):\n","        seq, pool = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n","        output = F.relu(self.pre_classifier(pool))\n","        output = self.dropout(output)\n","        return self.classifier(output)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"7zwZ-mxjepuz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["b909c4b8a71c4878b721d0e8c26cde16","c63f078587aa435a80c659ed6eac5030","a3e06726e587484dab11d1658f537fac","d69a880ad722475e9d189cc4c81602f4","08dfc8f1d2e6495fbceef929d84d31f1","7a3575b043894cc0bf69549851aee20b","9419597e3f2e405293a032f4b976553c","a32c674bb55d4c93957be656df874a8c","cc24ddcbe0ad4a0ca4b9a8374e5748dd","adc60a63d82b48e9b6a9a1e8dc3017b5","b1a76dc6b43a4515b2ecad108243b860","36692c11bf24498c86ad13afec5970f4","80efeda32e6646f19851e0c203a536b9","a9ecd68c790443c9bd6c73e1398fe70e","a6575818001f47278751346adf84f6f6","3a049448edc8457e8d2c28d5a8e31d41"]},"executionInfo":{"status":"ok","timestamp":1599939165792,"user_tz":420,"elapsed":33141,"user":{"displayName":"Dillon Quan","photoUrl":"","userId":"05921916562389664894"}},"outputId":"c8a37cd5-45e2-4ba0-eb92-863978fdf311"},"source":["model = BERT(.3)\n","model.to(device)"],"execution_count":14,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b909c4b8a71c4878b721d0e8c26cde16","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cc24ddcbe0ad4a0ca4b9a8374e5748dd","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["BERT(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n","  (classifier): Linear(in_features=768, out_features=1, bias=True)\n","  (dropout): Dropout(p=0.3, inplace=False)\n",")"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"AhhhFvFtfkcB","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599942620348,"user_tz":420,"elapsed":403,"user":{"displayName":"Dillon Quan","photoUrl":"","userId":"05921916562389664894"}}},"source":["def train_model(model, train_dl, valid_dl, optimizer, epochs):\n","    for epoch in range(epochs):\n","        model.train()\n","        total_loss, total, n_correct = 0, 0, 0\n","        \n","        for idx, data in enumerate(train_dl):\n","            ids = data[0].to(device)\n","            mask = data[1].to(device)\n","            targets = torch.LongTensor(data[2]).to(device)\n","            batch_size = targets.shape[0]\n","\n","            y_pred = model(ids, mask)\n","            loss = F.binary_cross_entropy_with_logits(y_pred, targets.float().unsqueeze(1))\n","            total_loss += loss.item() * batch_size\n","            total += batch_size\n","            out = (y_pred >= 0.5).float().squeeze()\n","            n_correct += out.eq(targets).sum().item()\n","\n","            if idx % 100 == 0:\n","                print(f\"Training Loss per 100 steps: {total_loss / total}\")\n","                print(f\"Training Accuracy per 100 steps: {n_correct/total}\")\n","\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","        \n","        val_loss, val_acc = valid_model(model, valid_dl)\n","        print(f\"Epoch {epoch+1} Training Loss: {total_loss/total} Training Accuracy: {n_correct/total} Valid Loss: {val_loss} Valid Accuracy: {val_acc}\")    "],"execution_count":72,"outputs":[]},{"cell_type":"code","metadata":{"id":"18xVSolzf2ZR","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599942622853,"user_tz":420,"elapsed":455,"user":{"displayName":"Dillon Quan","photoUrl":"","userId":"05921916562389664894"}}},"source":["def valid_model(model, valid_dl):\n","    model.eval()\n","    total_loss, total, n_correct = 0, 0, 0\n","    for data in valid_dl:\n","        ids = data[0].to(device)\n","        mask = data[1].to(device)\n","        targets = torch.LongTensor(data[2]).to(device)\n","        batch_size = targets.shape[0]\n","\n","        y_pred = model(ids, mask)\n","        loss = F.binary_cross_entropy(torch.sigmoid(y_pred), targets.float().unsqueeze(1))\n","        total_loss += loss.item() * batch_size\n","        total += batch_size\n","        out = (y_pred >= 0.5).float().squeeze()\n","        n_correct += out.eq(targets).sum().item()\n","\n","    return total_loss/total, n_correct/total"],"execution_count":73,"outputs":[]},{"cell_type":"code","metadata":{"id":"pQb-V794f7de","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":802},"outputId":"35f79810-7a8a-4cfa-bcd9-251a591a0334"},"source":["optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n","train_model(model, train_dl, valid_dl, optimizer, EPOCHS)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Training Loss per 100 steps: 0.0057329232804477215\n","Training Accuracy per 100 steps: 1.0\n","Training Loss per 100 steps: 0.058381374739802046\n","Training Accuracy per 100 steps: 0.9832920792079208\n","Training Loss per 100 steps: 0.07066349477671661\n","Training Accuracy per 100 steps: 0.9791666666666666\n","Training Loss per 100 steps: 0.07334175968637065\n","Training Accuracy per 100 steps: 0.9775747508305648\n","Training Loss per 100 steps: 0.07907062089401634\n","Training Accuracy per 100 steps: 0.9738154613466334\n","Epoch 1 Training Loss: 0.07811889574394631 Training Accuracy: 0.974561403508772 Valid Loss: 0.7202749164575795 Valid Accuracy: 0.8158971361776739\n","Training Loss per 100 steps: 0.017747756093740463\n","Training Accuracy per 100 steps: 1.0\n","Training Loss per 100 steps: 0.056130996077681086\n","Training Accuracy per 100 steps: 0.9746287128712872\n","Training Loss per 100 steps: 0.06342475089552668\n","Training Accuracy per 100 steps: 0.9760572139303483\n","Training Loss per 100 steps: 0.064611841165275\n","Training Accuracy per 100 steps: 0.9769518272425249\n","Training Loss per 100 steps: 0.06666773253676721\n","Training Accuracy per 100 steps: 0.9772443890274314\n","Epoch 2 Training Loss: 0.06767201226624 Training Accuracy: 0.9771929824561404 Valid Loss: 0.690306995520156 Valid Accuracy: 0.8059614260666277\n","Training Loss per 100 steps: 0.017326470464468002\n","Training Accuracy per 100 steps: 1.0\n","Training Loss per 100 steps: 0.03246439124992357\n","Training Accuracy per 100 steps: 0.9913366336633663\n","Training Loss per 100 steps: 0.038951480685876894\n","Training Accuracy per 100 steps: 0.9878731343283582\n","Training Loss per 100 steps: 0.04182323601454237\n","Training Accuracy per 100 steps: 0.9858803986710963\n","Training Loss per 100 steps: 0.04426424449978587\n","Training Accuracy per 100 steps: 0.9858167082294265\n","Epoch 3 Training Loss: 0.04518307329738262 Training Accuracy: 0.985672514619883 Valid Loss: 0.6351237308009718 Valid Accuracy: 0.8194038573933372\n","Training Loss per 100 steps: 0.14560678601264954\n","Training Accuracy per 100 steps: 0.9375\n","Training Loss per 100 steps: 0.024491577177529804\n","Training Accuracy per 100 steps: 0.9919554455445545\n","Training Loss per 100 steps: 0.035568804549347535\n","Training Accuracy per 100 steps: 0.990360696517413\n","Training Loss per 100 steps: 0.035024182375348746\n","Training Accuracy per 100 steps: 0.9902408637873754\n","Training Loss per 100 steps: 0.038946220714702245\n","Training Accuracy per 100 steps: 0.9887780548628429\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nPklzkVRAF-U","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}